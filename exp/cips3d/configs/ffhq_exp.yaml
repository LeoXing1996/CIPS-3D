root_obs: &root_obs s3://bucket-3690/ZhouPeng
modelarts_download: &modelarts_download
  ffhq256:
    datapath_obs: '{global_cfg.root_obs}/keras/ffhq/downsample_ffhq_256x256.zip'
    datapath: "datasets/ffhq/downsample_ffhq_256x256.zip"
    overwrite: false
    eval: true
    unzip: true
  ffhq256_list:
    datapath_obs: '{global_cfg.root_obs}/keras/ffhq/ffhq_256.txt'
    datapath: "datasets/ffhq/ffhq_256.txt"
    overwrite: false
    eval: true
    unzip: false
  fid_inception:
    datapath_obs: '{global_cfg.root_obs}/keras/cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth'
    datapath: "/home/ma-user/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth"
    overwrite: false
    eval: true
    unzip: false


obs_ffhq_r256: &obs_ffhq_r256
  datapath_obs: 'keras/ffhq/downsample_ffhq_256x256.zip'
  datapath: "datasets/ffhq/downsample_ffhq_256x256.zip"
  disable: false
  overwrite: false
  unzip: false


G_cfg_3D2D: &G_cfg_3D2D
  register_modules:
  - exp.cips3d.models.generator
  name: exp.cips3d.models.generator.GeneratorNerfINR
  z_dim: 256
  optim:
    lr: 0.0002
    equal_lr: 0.001
  nerf_cfg:
    in_dim: 3
#    hidden_dim: 256
    hidden_dim: 128
    hidden_layers: 2
    rgb_dim: 32
#    style_dim: 256
    style_dim: 128
  mapping_nerf_cfg:
    z_dim: 256
#    hidden_dim: 256
    hidden_dim: 128
    base_layers: 4
    head_layers: 0
  inr_cfg:
    input_dim: 32
#    style_dim: 256
#    hidden_dim: 256
    style_dim: 512
    hidden_dim: 512
#    pre_rgb_dim: 32
    pre_rgb_dim: 3
  mapping_inr_cfg:
    z_dim: 512
#    hidden_dim: 256
    hidden_dim: 512
#    base_layers: 4
    base_layers: 8
    head_layers: 0
    add_norm: true
    norm_out: true

_build_generator:
  G_cfg: *G_cfg_3D2D
  network_pkl: cache_pretrained/cips3d/G_ema_ffhq.pth


D_cfg: &D_cfg
  register_modules:
    - exp.cips3d.models.discriminator
  name: exp.cips3d.models.discriminator.Discriminator_MultiScale_Aux
  diffaug: false
  max_size: 1024
  channel_multiplier: 2
  first_downsample: false
  stddev_group: 0

_build_discriminator:
  D_cfg: *D_cfg
#  network_pkl: cache_pretrained/cips3d/G_ema_ffhq.pth


dataset_ffhq_r256: &dataset_ffhq_r256
  register_modules:
    - "tl2.proj.pytorch.examples.dataset_stylegan3.dataset"
  name: "ImageFolderDataset_of_stylegan"
  path: 'datasets/ffhq/downsample_ffhq_256x256.zip'
  use_labels: False
  max_size: null
#  max_size: 100
  xflip: True
  resize_resolution: null
#  resize_resolution: 1024
  random_seed: 0


G_kwargs: &G_kwargs
  fov: 12
  ray_start: 0.88
  ray_end: 1.12
  num_steps: 12
  h_stddev: 0.3
  v_stddev: 0.155
  hierarchical_sample: true
  psi: 1.
  sample_dist: 'gaussian'


train_ffhq:
  seed: 1234
  G_cfg: *G_cfg_3D2D
  D_cfg: *D_cfg
  data_cfg: *dataset_ffhq_r256
  root_obs: *root_obs
  obs_training_dataset: *obs_ffhq_r256
  G_kwargs: *G_kwargs
  # train
  use_amp_G: false
  use_amp_D: false
  gen_lr: 0.0002
  disc_lr: 0.002
  betas: [0, 0.999]
  fixed_z_bs: 25
  total_iters: 200000
  batch_size: 4
  batch_split: 2
  img_size: 32
  num_workers: 8
  diffaug: false

  log_every: 100
  log_img_every: 500
  eval_every: 500

  num_images_real_eval: 2048
  num_images_gen_eval: 2048
  forward_points: 256
  grad_points: 256
  main_aux_mask: [1., 1.]
  train_aux_img: true
  update_aux_every: 1
  warmup_itrs: 0
  mul_lr: 1.
  reset_best_fid: true
  load_G_ema: true
  load_optimizers: true
  D_first_layer_warmup: true
  d_reg_every: 1
  use_diffaug: false
  curriculum:
    new_attrs:
      horizontal_flip: true
      image_list_file: "datasets/ffhq/images256x256_image_list.txt"
    dataset: FFHQ
    latent_dim: 256
    topk_v: 0.
    fade_steps: 10000

    pos_lambda: 0.
    r1_lambda: 10.
    grad_clip: 10
    '0':
      num_steps: 12
  modelarts_download: *modelarts_download

train_ffhq_r128:
  base: train_ffhq
  curriculum:
    '0':
      img_size: 128
      gen_lr: 0.0001
      disc_lr: 0.001










